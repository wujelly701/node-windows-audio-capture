# ğŸš€ å¿«é€Ÿå…¥é—¨æŒ‡å— - node-windows-audio-capture v2.9.0

**é€‚ç”¨ç‰ˆæœ¬**: v2.9.0  
**æ›´æ–°æ—¥æœŸ**: 2025-10-17  
**ç›®æ ‡ç”¨æˆ·**: æ‰€æœ‰éœ€è¦ Windows éŸ³é¢‘æ•è·çš„å¼€å‘è€…

---

## ğŸ“‹ ç›®å½•

- [30 ç§’å¿«é€Ÿä¸Šæ‰‹](#30-ç§’å¿«é€Ÿä¸Šæ‰‹)
- [æ–°åŠŸèƒ½: éº¦å…‹é£æ•è·](#æ–°åŠŸèƒ½-éº¦å…‹é£æ•è·)
- [å®‰è£…](#å®‰è£…)
- [æ ¸å¿ƒåŠŸèƒ½æ¦‚è§ˆ](#æ ¸å¿ƒåŠŸèƒ½æ¦‚è§ˆ)
- [åŸºç¡€ä½¿ç”¨](#åŸºç¡€ä½¿ç”¨)
- [è¿›é˜¶åŠŸèƒ½](#è¿›é˜¶åŠŸèƒ½)
- [å®Œæ•´ç¤ºä¾‹](#å®Œæ•´ç¤ºä¾‹)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æ›´å¤šèµ„æº](#æ›´å¤šèµ„æº)

---

## 30 ç§’å¿«é€Ÿä¸Šæ‰‹

### ç³»ç»ŸéŸ³é¢‘æ•è·

```javascript
const { AudioCapture, getProcesses } = require('node-windows-audio-capture');

// 1. æšä¸¾è¿›ç¨‹
const processes = await getProcesses();
console.log('å¯ç”¨è¿›ç¨‹:', processes);

// 2. é€‰æ‹© Chrome è¿›ç¨‹
const chrome = processes.find(p => p.name.includes('chrome'));

// 3. åˆ›å»ºæ•è·å®ä¾‹
const capture = new AudioCapture({ processId: chrome.pid });

// 4. å¯ç”¨éŸ³é¢‘æ•ˆæœ
capture.setDenoiseEnabled(true);  // AI é™å™ª
capture.setAGCEnabled(true);      // éŸ³é‡å½’ä¸€åŒ–
capture.setEQEnabled(true);       // äººå£°å¢å¼º

// 5. ç›‘å¬éŸ³é¢‘æ•°æ®
capture.on('data', (event) => {
  const audioBuffer = event.buffer;  // Float32Array
  console.log('æ”¶åˆ°éŸ³é¢‘:', audioBuffer.length, 'æ ·æœ¬');
});

// 6. å¯åŠ¨æ•è·
await capture.start();
```

### éº¦å…‹é£æ•è· ğŸ™ï¸ (v2.9.0 æ–°å¢)

```javascript
const { MicrophoneCapture } = require('node-windows-audio-capture');

// 1. åˆ›å»ºéº¦å…‹é£æ•è·å®ä¾‹
const mic = new MicrophoneCapture({
  denoise: true,  // RNNoise é™å™ª
  agc: true,      // è‡ªåŠ¨å¢ç›Š
  eq: true        // å‡è¡¡å™¨
});

// 2. ç›‘å¬éŸ³é¢‘æ•°æ®
mic.on('data', (event) => {
  const audioBuffer = event.buffer;  // Float32Array
  console.log('éº¦å…‹é£éŸ³é¢‘:', audioBuffer.length, 'æ ·æœ¬');
});

// 3. å¯åŠ¨æ•è·
await mic.start();
```

**å°±è¿™ä¹ˆç®€å•ï¼** ğŸ‰

---

## æ–°åŠŸèƒ½: éº¦å…‹é£æ•è·

### ğŸ™ï¸ v2.9.0 æ–°å¢å®Œæ•´éº¦å…‹é£æ•è·æ”¯æŒ

```javascript
const { MicrophoneCapture, listDevices } = require('node-windows-audio-capture');

// åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è®¾å¤‡
const devices = await listDevices();
const microphones = devices.filter(d => !d.isLoopback);

console.log('å¯ç”¨éº¦å…‹é£:');
microphones.forEach(mic => {
  console.log(`  ${mic.name} (${mic.id})`);
});

// é€‰æ‹©ç‰¹å®šéº¦å…‹é£
const mic = new MicrophoneCapture({
  deviceId: microphones[0].id,
  denoise: true,
  agc: true,
  eq: true
});

mic.on('data', (event) => {
  console.log('éº¦å…‹é£éŸ³é¢‘:', event.buffer.length, 'æ ·æœ¬');
});

await mic.start();
```

**é€‚ç”¨åœºæ™¯**:
- âœ… è¯­éŸ³è¯†åˆ« (ASR)
- âœ… å®æ—¶ç¿»è¯‘
- âœ… ä¼šè®®å½•éŸ³
- âœ… æ’­å®¢å½•åˆ¶
- âœ… è¯­éŸ³åŠ©æ‰‹

---

## å®‰è£…

### æ–¹å¼ 1: ä» GitHub Release å®‰è£…ï¼ˆæ¨èï¼‰

```bash
npm install https://github.com/wujelly701/node-windows-audio-capture/tarball/v2.9.0
```

**ä¼˜åŠ¿**:
- âœ… åŒ…å«é¢„ç¼–è¯‘äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆwin32-x64ï¼‰
- âœ… æ— éœ€ Visual Studio æˆ–å…¶ä»–ç¼–è¯‘å·¥å…·
- âœ… å®‰è£…å³ç”¨

### æ–¹å¼ 2: ä» npm å®‰è£…ï¼ˆå¦‚å·²å‘å¸ƒï¼‰

```bash
npm install node-windows-audio-capture@2.9.0
```

### æ–¹å¼ 3: ä»æºç å®‰è£…ï¼ˆå¼€å‘è€…ï¼‰

```bash
git clone https://github.com/wujelly701/node-windows-audio-capture.git
cd node-windows-audio-capture
git checkout v2.9.0
npm install
npm run build
```

**è¦æ±‚**:
- Visual Studio 2017 æˆ–æ›´é«˜ç‰ˆæœ¬
- Windows SDK
- Python 3.x

---

## æ ¸å¿ƒåŠŸèƒ½æ¦‚è§ˆ

| åŠŸèƒ½ | ç‰ˆæœ¬ | è¯´æ˜ | ç”¨é€” |
|------|-----|------|------|
| **è¿›ç¨‹çº§éŸ³é¢‘æ•è·** | v1.0 | æ•è·æŒ‡å®šè¿›ç¨‹çš„éŸ³é¢‘è¾“å‡º | ç²¾å‡†æ•è·ç‰¹å®šåº”ç”¨ |
| **åŠ¨æ€é™éŸ³æ§åˆ¶** | v2.1 | è‡ªåŠ¨é™éŸ³éç›®æ ‡è¿›ç¨‹ | 90%+ éŸ³é¢‘çº¯åº¦ |
| **ASR æ ¼å¼è½¬æ¢** | v2.2 | Int16, 16kHz, Mono | ç›´è¿è¯­éŸ³è¯†åˆ« API |
| **è®¾å¤‡çƒ­æ’æ‹”** | v2.3 | è‡ªåŠ¨æ£€æµ‹è®¾å¤‡å˜åŒ– | è®¾å¤‡åˆ‡æ¢æ— éœ€é‡å¯ |
| **é«˜æ€§èƒ½é‡‡æ ·** | v2.5 | Kaiser çª— Sinc æ’å€¼ | 42% æ›´å¿«ï¼Œ-70dB è¡°å‡ |
| **è‡ªé€‚åº”ç¼“å†²æ± ** | v2.6 | åŠ¨æ€è°ƒæ•´å†…å­˜æ±  | 371% Hit Rate æå‡ |
| **RNNoise é™å™ª** | v2.7 | AI æ·±åº¦å­¦ä¹ é™å™ª | VAD + å®æ—¶é™å™ª |
| **AGC + 3-Band EQ** | v2.8 | éŸ³é‡å½’ä¸€åŒ– + å‡è¡¡å™¨ | ä¸“ä¸šéŸ³é¢‘å¤„ç† |
| **ğŸ™ï¸ éº¦å…‹é£æ•è·** | v2.9 | è®¾å¤‡çº§éº¦å…‹é£å½•åˆ¶ | è¯­éŸ³è¯†åˆ«/ç¿»è¯‘ |
| **ğŸ”Š Sinc é‡é‡‡æ ·** | v2.9 | é«˜è´¨é‡ ASR è½¬æ¢ | æ˜¾è‘—æå‡éŸ³è´¨ |
| **AI é™å™ª** | v2.7 | RNNoise æ·±åº¦å­¦ä¹  | å®æ—¶æ¶ˆé™¤èƒŒæ™¯å™ªéŸ³ |
| **AGC éŸ³é‡å½’ä¸€åŒ–** | v2.8 | RMS è‡ªåŠ¨å¢ç›Šæ§åˆ¶ | ç¨³å®šè¾“å‡ºéŸ³é‡ |
| **3-Band EQ** | v2.8 | ä½/ä¸­/é«˜é¢‘å‡è¡¡ | ä¼˜åŒ–éŸ³è´¨/äººå£° |

---

## åŸºç¡€ä½¿ç”¨

### 1. æšä¸¾éŸ³é¢‘è¿›ç¨‹

```javascript
const { getProcesses } = require('node-windows-audio-capture');

// è·å–æ‰€æœ‰æœ‰éŸ³é¢‘è¾“å‡ºçš„è¿›ç¨‹
const processes = await getProcesses();

processes.forEach(proc => {
  console.log(`è¿›ç¨‹: ${proc.name}`);
  console.log(`  PID: ${proc.pid}`);
  console.log(`  éŸ³é¢‘ä¼šè¯: ${proc.audioSessionCount}`);
});

// è¾“å‡ºç¤ºä¾‹:
// è¿›ç¨‹: chrome.exe
//   PID: 12345
//   éŸ³é¢‘ä¼šè¯: 2
// è¿›ç¨‹: potplayer.exe
//   PID: 6789
//   éŸ³é¢‘ä¼šè¯: 1
```

### 2. åˆ›å»ºéŸ³é¢‘æ•è·å®ä¾‹

```javascript
const { AudioCapture } = require('node-windows-audio-capture');

const capture = new AudioCapture({
  processId: 12345,           // ç›®æ ‡è¿›ç¨‹ PID
  sampleRate: 48000,          // é‡‡æ ·ç‡ (Hz)
  channels: 2,                // å£°é“æ•° (1=å•å£°é“, 2=ç«‹ä½“å£°)
  // WASAPI å§‹ç»ˆè¾“å‡º Float32 æ ¼å¼
  useExternalBuffer: true,    // ä½¿ç”¨å¤–éƒ¨ç¼“å†²æ± 
  bufferPoolStrategy: 'adaptive'  // è‡ªé€‚åº”ç¼“å†²æ± ç­–ç•¥
});
```

### 3. ç›‘å¬éŸ³é¢‘æ•°æ®

```javascript
capture.on('data', (event) => {
  const audioBuffer = event.buffer;  // Float32Array æˆ– Int16Array
  const timestamp = event.timestamp; // æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
  const frameCount = event.frameCount; // å¸§æ•°
  
  // å¤„ç†éŸ³é¢‘æ•°æ®
  processAudio(audioBuffer);
});
```

### 4. å¯åŠ¨å’Œåœæ­¢

```javascript
// å¯åŠ¨æ•è·
await capture.start();
console.log('âœ… éŸ³é¢‘æ•è·å·²å¯åŠ¨');

// åœæ­¢æ•è·
await capture.stop();
console.log('â¹ï¸ éŸ³é¢‘æ•è·å·²åœæ­¢');
```

### 5. é”™è¯¯å¤„ç†

```javascript
capture.on('error', (error) => {
  console.error('é”™è¯¯:', error.message);
  console.error('é”™è¯¯ç :', error.code);
  
  switch (error.code) {
    case 'PROCESS_NOT_FOUND':
      console.log('ç›®æ ‡è¿›ç¨‹å·²å…³é—­');
      break;
    case 'AUDIO_DEVICE_ERROR':
      console.log('éŸ³é¢‘è®¾å¤‡é”™è¯¯');
      break;
    case 'INVALID_STATE':
      console.log('çŠ¶æ€æ— æ•ˆ');
      break;
    default:
      console.log('æœªçŸ¥é”™è¯¯');
  }
});
```

---

## è¿›é˜¶åŠŸèƒ½

### v2.1: åŠ¨æ€é™éŸ³æ§åˆ¶

**è‡ªåŠ¨éš”ç¦»éç›®æ ‡è¿›ç¨‹ï¼Œç¡®ä¿ 90%+ éŸ³é¢‘çº¯åº¦**

```javascript
// å¯ç”¨åŠ¨æ€é™éŸ³
capture.setMuteOtherProcesses(true);

// è®¾ç½®ç™½åå•ï¼ˆå…è®¸è¿™äº›è¿›ç¨‹å‘å£°ï¼‰
const allowList = [12345, 67890];  // å…è®¸çš„ PID
capture.setAllowList(allowList);

// è®¾ç½®é»‘åå•ï¼ˆå¼ºåˆ¶é™éŸ³è¿™äº›è¿›ç¨‹ï¼‰
const blockList = [11111, 22222];  // è¦å±è”½çš„ PID
capture.setBlockList(blockList);

// æŸ¥è¯¢å½“å‰çŠ¶æ€
const isMuting = capture.isMutingOtherProcesses();  // true/false
const currentAllowList = capture.getAllowList();     // [12345, 67890]
const currentBlockList = capture.getBlockList();     // [11111, 22222]
```

**ä½¿ç”¨åœºæ™¯**:
- ğŸ® æ¸¸æˆå½•åˆ¶ - åªå½•æ¸¸æˆéŸ³ï¼Œå±è”½ QQ/å¾®ä¿¡
- ğŸ“¹ ä¼šè®®å½•åˆ¶ - åªå½• Zoom éŸ³é¢‘ï¼Œå±è”½éŸ³ä¹æ’­æ”¾å™¨
- ğŸ¬ è§†é¢‘ç¿»è¯‘ - åªæ•è·æµè§ˆå™¨æ ‡ç­¾é¡µéŸ³é¢‘

---

### v2.7: AI é™å™ªï¼ˆRNNoiseï¼‰

**å®æ—¶æ¶ˆé™¤é”®ç›˜å£°ã€é£æ‰‡å£°ã€èƒŒæ™¯å™ªéŸ³**

```javascript
// å¯ç”¨ AI é™å™ª
capture.setDenoiseEnabled(true);

// æ£€æŸ¥é™å™ªçŠ¶æ€
const isEnabled = capture.getDenoiseEnabled();  // true

// è·å–é™å™ªç»Ÿè®¡ä¿¡æ¯
const stats = capture.getDenoiseStats();
console.log('é™å™ªç»Ÿè®¡:');
console.log('  VAD æ¦‚ç‡:', (stats.vadProbability * 100).toFixed(1) + '%');
console.log('  å¤„ç†å¸§æ•°:', stats.framesProcessed);

// è¾“å‡ºç¤ºä¾‹:
// é™å™ªç»Ÿè®¡:
//   VAD æ¦‚ç‡: 87.3%
//   å¤„ç†å¸§æ•°: 48000
```

**VAD (Voice Activity Detection)**:
- **0-30%**: å™ªéŸ³ï¼ˆé£æ‰‡ã€ç©ºè°ƒï¼‰
- **30-70%**: æ··åˆï¼ˆéŸ³ä¹ã€ç¯å¢ƒå£°ï¼‰
- **70-100%**: æ¸…æ™°è¯­éŸ³

**æ€§èƒ½**:
- å»¶è¿Ÿ: < 10ms
- CPU: < 5%
- å†…å­˜: ~4 KB

---

### v2.8: AGC éŸ³é‡å½’ä¸€åŒ–

**è‡ªåŠ¨è°ƒæ•´éŸ³é‡ï¼Œé¿å…å¿½å¤§å¿½å°**

```javascript
// å¯ç”¨ AGC
capture.setAGCEnabled(true);

// é…ç½® AGC å‚æ•°
capture.setAGCOptions({
  targetLevel: -18,    // ç›®æ ‡éŸ³é‡ (dBFS, -30 åˆ° 0)
  maxGain: 25,         // æœ€å¤§å¢ç›Š (dB, 0 åˆ° 50)
  minGain: -5,         // æœ€å°å¢ç›Š (dB, -20 åˆ° 0)
  attackTime: 10,      // å“åº”æ—¶é—´ (ms, 5 åˆ° 200)
  releaseTime: 100     // é‡Šæ”¾æ—¶é—´ (ms, 50 åˆ° 500)
});

// è·å–å½“å‰é…ç½®
const options = capture.getAGCOptions();
console.log('AGC é…ç½®:', options);

// è·å–å®æ—¶ç»Ÿè®¡
const stats = capture.getAGCStats();
console.log('AGC ç»Ÿè®¡:');
console.log('  å½“å‰å¢ç›Š:', stats.currentGain.toFixed(2), 'dB');
console.log('  å¹³å‡éŸ³é‡:', stats.averageLevel.toFixed(2), 'dBFS');
console.log('  æ˜¯å¦å‰Šæ³¢:', stats.clipping);

// è¾“å‡ºç¤ºä¾‹:
// AGC ç»Ÿè®¡:
//   å½“å‰å¢ç›Š: 12.34 dB
//   å¹³å‡éŸ³é‡: -18.56 dBFS
//   æ˜¯å¦å‰Šæ³¢: false
```

**æ¨èé…ç½®**:

| åœºæ™¯ | targetLevel | maxGain | attackTime | releaseTime |
|------|-------------|---------|------------|-------------|
| è¯­éŸ³èŠå¤© | -18 | 25 | 8 | 80 |
| éŸ³ä¹æ’­æ”¾ | -20 | 15 | 20 | 150 |
| æ¸¸æˆéŸ³é¢‘ | -20 | 20 | 12 | 100 |
| ä¼šè®®å½•éŸ³ | -18 | 30 | 10 | 100 |

---

### v2.8: 3-Band EQ å‡è¡¡å™¨

**è°ƒæ•´ä½/ä¸­/é«˜é¢‘ï¼Œä¼˜åŒ–éŸ³è´¨**

```javascript
// å¯ç”¨ EQ
capture.setEQEnabled(true);

// è®¾ç½®å„é¢‘æ®µå¢ç›Š
capture.setEQBandGain('low', 6);    // ä½é¢‘ +6 dB (< 500 Hz)
capture.setEQBandGain('mid', 0);    // ä¸­é¢‘ 0 dB (500-4000 Hz)
capture.setEQBandGain('high', 3);   // é«˜é¢‘ +3 dB (> 4000 Hz)

// è·å–å¢ç›Šå€¼
const lowGain = capture.getEQBandGain('low');    // 6
const midGain = capture.getEQBandGain('mid');    // 0
const highGain = capture.getEQBandGain('high');  // 3

// è·å– EQ ç»Ÿè®¡
const stats = capture.getEQStats();
console.log('EQ ç»Ÿè®¡:', stats);
// è¾“å‡º: { enabled: true, lowGain: 6, midGain: 0, highGain: 3, framesProcessed: 96000 }
```

**EQ é¢„è®¾**:

**1. æµè¡ŒéŸ³ä¹** - å¢å¼ºä½éŸ³å’Œé«˜éŸ³
```javascript
capture.setEQBandGain('low', 6);
capture.setEQBandGain('mid', 0);
capture.setEQBandGain('high', 3);
```

**2. äººå£°å¢å¼º** - çªå‡ºä¸­é¢‘äººå£°
```javascript
capture.setEQBandGain('low', -3);   // å‡å°‘ä½é¢‘å™ªéŸ³
capture.setEQBandGain('mid', 5);    // å¢å¼ºäººå£°
capture.setEQBandGain('high', 2);   // è½»å¾®å¢å¼ºæ¸…æ™°åº¦
```

**3. å¤å…¸éŸ³ä¹** - å¹³è¡¡åŠ é«˜é¢‘ç»†èŠ‚
```javascript
capture.setEQBandGain('low', 2);
capture.setEQBandGain('mid', 0);
capture.setEQBandGain('high', 4);
```

**4. ç”µå­éŸ³ä¹** - é‡ä½éŸ³åŠ é«˜é¢‘
```javascript
capture.setEQBandGain('low', 10);
capture.setEQBandGain('mid', -2);
capture.setEQBandGain('high', 6);
```

---

### v2.2: ASR æ ¼å¼è½¬æ¢

**ä¸€è¡Œä»£ç è½¬ä¸ºè¯­éŸ³è¯†åˆ«å‹å¥½æ ¼å¼**

```javascript
const AudioProcessingPipeline = require('node-windows-audio-capture/lib/audio-processing-pipeline');

// åˆ›å»ºè½¬æ¢ç®¡é“ï¼ˆé˜¿é‡Œäº‘ ASR é¢„è®¾ï¼‰
const pipeline = new AudioProcessingPipeline('china-asr', {
  quality: 'sinc'  // v2.5 é«˜æ€§èƒ½ Sinc æ’å€¼
});

capture.on('data', (event) => {
  // åŸå§‹: Float32, 48kHz, Stereo - 920 KB/ç§’
  const rawAudio = event.buffer;
  
  // è½¬æ¢: Int16, 16kHz, Mono - 76.8 KB/ç§’
  const asrAudio = pipeline.process(rawAudio);
  
  // ç›´æ¥å‘é€åˆ° ASR API
  sendToASR(asrAudio);
});
```

**æ€§èƒ½æŒ‡æ ‡**:
- å‹ç¼©æ¯”: 12:1 (920 KB â†’ 76.8 KB)
- å»¶è¿Ÿ: < 3ms (v2.5 ä¼˜åŒ–)
- CPU: < 3%

**æ”¯æŒçš„ ASR é¢„è®¾**:
- `china-asr` - é˜¿é‡Œäº‘/ç™¾åº¦/è…¾è®¯
- `openai-whisper` - OpenAI Whisper
- `azure-speech` - Azure Speech
- `google-cloud` - Google Cloud Speech
- `aws-transcribe` - AWS Transcribe
- `generic-asr` - é€šç”¨é…ç½®

---

### v2.6: ç¼“å†²æ± ç®¡ç†

**æŸ¥è¯¢ç¼“å†²æ± ç»Ÿè®¡ä¿¡æ¯**

```javascript
const stats = capture.getPoolStats();

console.log('ç¼“å†²æ± ç»Ÿè®¡:');
console.log('  åˆ†é…æ¬¡æ•°:', stats.allocations);
console.log('  é‡ç”¨æ¬¡æ•°:', stats.reuses);
console.log('  é‡ç”¨ç‡:', (stats.reuseRate * 100).toFixed(2) + '%');
console.log('  å½“å‰æ± å¤§å°:', stats.currentPoolSize);

// è¾“å‡ºç¤ºä¾‹:
// ç¼“å†²æ± ç»Ÿè®¡:
//   åˆ†é…æ¬¡æ•°: 1000
//   é‡ç”¨æ¬¡æ•°: 950
//   é‡ç”¨ç‡: 95.00%
//   å½“å‰æ± å¤§å°: 120
```

**v2.6 è‡ªé€‚åº”æ± ä¼˜åŠ¿**:
- è‡ªåŠ¨è°ƒæ•´æ± å¤§å°ï¼ˆ50-200ï¼‰
- Hit Rate æå‡ 371.6% (0.67% â†’ 3.14%)
- æ— éœ€æ‰‹åŠ¨è°ƒå‚

---

## å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹ 1: è¯­éŸ³è¯†åˆ«ï¼ˆWhisper APIï¼‰

```javascript
const { AudioCapture, getProcesses } = require('node-windows-audio-capture');
const AudioProcessingPipeline = require('node-windows-audio-capture/lib/audio-processing-pipeline');
const axios = require('axios');

async function startSpeechRecognition() {
  // 1. æšä¸¾è¿›ç¨‹
  const processes = await getProcesses();
  const chrome = processes.find(p => p.name.includes('chrome'));
  
  if (!chrome) {
    console.error('æœªæ‰¾åˆ° Chrome è¿›ç¨‹');
    return;
  }

  // 2. åˆ›å»ºæ•è·å®ä¾‹
  const capture = new AudioCapture({
    processId: chrome.pid,
    useExternalBuffer: true,
    bufferPoolStrategy: 'adaptive'
  });

  // 3. å¯ç”¨ AI å¤„ç†
  capture.setDenoiseEnabled(true);   // AI é™å™ª
  capture.setAGCEnabled(true);       // éŸ³é‡å½’ä¸€åŒ–
  capture.setAGCOptions({
    targetLevel: -18,
    maxGain: 25,
    attackTime: 10,
    releaseTime: 100
  });
  capture.setEQEnabled(true);        // äººå£°å¢å¼º
  capture.setEQBandGain('low', -3);
  capture.setEQBandGain('mid', 5);
  capture.setEQBandGain('high', 2);
  capture.setMuteOtherProcesses(true);  // éš”ç¦»å…¶ä»–è¿›ç¨‹

  // 4. åˆ›å»º ASR è½¬æ¢ç®¡é“
  const pipeline = new AudioProcessingPipeline('openai-whisper', {
    quality: 'sinc'
  });

  // 5. éŸ³é¢‘ç¼“å†²
  let audioQueue = [];
  const BATCH_SIZE = 10;  // ç´¯ç§¯ 10 ä¸ªéŸ³é¢‘å—å†å‘é€

  capture.on('data', (event) => {
    // è½¬æ¢ä¸º ASR æ ¼å¼
    const asrAudio = pipeline.process(event.buffer);
    audioQueue.push(asrAudio);

    // è¾¾åˆ°æ‰¹é‡å¤§å°ï¼Œå‘é€åˆ° Whisper
    if (audioQueue.length >= BATCH_SIZE) {
      const mergedAudio = mergeAudioBuffers(audioQueue);
      sendToWhisper(mergedAudio);
      audioQueue = [];
    }
  });

  // 6. ç›‘å¬ç»Ÿè®¡
  setInterval(() => {
    const denoiseStats = capture.getDenoiseStats();
    const agcStats = capture.getAGCStats();
    const eqStats = capture.getEQStats();

    console.log(`ğŸ”‡ é™å™ª VAD: ${(denoiseStats.vadProbability * 100).toFixed(1)}%`);
    console.log(`âš¡ AGC å¢ç›Š: ${agcStats.currentGain.toFixed(2)} dB`);
    console.log(`ğŸ›ï¸ EQ: Low ${eqStats.lowGain}dB, Mid ${eqStats.midGain}dB, High ${eqStats.highGain}dB`);
  }, 2000);

  // 7. å¯åŠ¨
  await capture.start();
  console.log('âœ… è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨');

  // 8. é”™è¯¯å¤„ç†
  capture.on('error', (error) => {
    console.error('é”™è¯¯:', error.message);
  });
}

// å‘é€åˆ° Whisper API
async function sendToWhisper(audioBuffer) {
  try {
    const response = await axios.post('https://api.openai.com/v1/audio/transcriptions', {
      file: audioBuffer,
      model: 'whisper-1'
    }, {
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'multipart/form-data'
      }
    });

    const text = response.data.text;
    console.log('è¯†åˆ«ç»“æœ:', text);
  } catch (error) {
    console.error('Whisper API é”™è¯¯:', error.message);
  }
}

// åˆå¹¶éŸ³é¢‘ç¼“å†²åŒº
function mergeAudioBuffers(buffers) {
  const totalLength = buffers.reduce((sum, buf) => sum + buf.length, 0);
  const merged = new Int16Array(totalLength);
  let offset = 0;
  
  for (const buffer of buffers) {
    merged.set(buffer, offset);
    offset += buffer.length;
  }
  
  return merged;
}

// å¯åŠ¨
startSpeechRecognition();
```

---

### ç¤ºä¾‹ 2: å®æ—¶å­—å¹•ç¿»è¯‘

```javascript
const { AudioCapture, getProcesses } = require('node-windows-audio-capture');
const AudioProcessingPipeline = require('node-windows-audio-capture/lib/audio-processing-pipeline');

async function startRealtimeSubtitles() {
  // 1. é€‰æ‹©è¿›ç¨‹
  const processes = await getProcesses();
  console.log('å¯ç”¨è¿›ç¨‹:');
  processes.forEach((p, i) => {
    console.log(`  ${i + 1}. ${p.name} (PID: ${p.pid})`);
  });

  const readline = require('readline').createInterface({
    input: process.stdin,
    output: process.stdout
  });

  readline.question('é€‰æ‹©è¿›ç¨‹ç¼–å·: ', async (answer) => {
    const index = parseInt(answer) - 1;
    const selectedProcess = processes[index];
    
    if (!selectedProcess) {
      console.error('æ— æ•ˆé€‰æ‹©');
      process.exit(1);
    }

    // 2. åˆ›å»ºæ•è·å®ä¾‹
    const capture = new AudioCapture({
      processId: selectedProcess.pid,
      useExternalBuffer: true,
      bufferPoolStrategy: 'adaptive'
    });

    // 3. å®Œæ•´ AI å¤„ç†é“¾
    capture.setDenoiseEnabled(true);
    capture.setAGCEnabled(true);
    capture.setAGCOptions({
      targetLevel: -20,
      maxGain: 20,
      attackTime: 12,
      releaseTime: 100
    });
    capture.setEQEnabled(true);
    capture.setEQBandGain('low', 2);
    capture.setEQBandGain('mid', 0);
    capture.setEQBandGain('high', 3);
    capture.setMuteOtherProcesses(true);

    // 4. ASR è½¬æ¢
    const pipeline = new AudioProcessingPipeline('china-asr', {
      quality: 'sinc'
    });

    // 5. éŸ³é¢‘æ•°æ®å¤„ç†
    capture.on('data', (event) => {
      const asrAudio = pipeline.process(event.buffer);
      
      // å‘é€åˆ° ASR å¼•æ“ï¼ˆè¿™é‡Œç”¨é˜¿é‡Œäº‘ Gummyï¼‰
      sendToGummyEngine(asrAudio);
    });

    // 6. å¯åŠ¨
    await capture.start();
    console.log(`âœ… æ­£åœ¨æ•è·: ${selectedProcess.name} (PID: ${selectedProcess.pid})`);
    console.log('æŒ‰ Ctrl+C åœæ­¢...');

    // 7. åœæ­¢å¤„ç†
    process.on('SIGINT', async () => {
      await capture.stop();
      console.log('\nâ¹ï¸ å·²åœæ­¢');
      process.exit(0);
    });

    readline.close();
  });
}

// å‘é€åˆ°é˜¿é‡Œäº‘ Gummyï¼ˆç¤ºä¾‹ï¼‰
function sendToGummyEngine(audioBuffer) {
  // å®ç° WebSocket è¿æ¥å’Œå‘é€é€»è¾‘
  // å‚è€ƒ: docs/TRANSLATION_SOFTWARE_INTEGRATION.md
}

startRealtimeSubtitles();
```

---

### ç¤ºä¾‹ 3: éŸ³é¢‘å½•åˆ¶ä¿å­˜

```javascript
const { AudioCapture, getProcesses } = require('node-windows-audio-capture');
const fs = require('fs');

async function recordAudio(processName, duration = 10) {
  // 1. æŸ¥æ‰¾è¿›ç¨‹
  const processes = await getProcesses();
  const target = processes.find(p => 
    p.name.toLowerCase().includes(processName.toLowerCase())
  );

  if (!target) {
    console.error(`æœªæ‰¾åˆ°è¿›ç¨‹: ${processName}`);
    return;
  }

  // 2. åˆ›å»ºæ•è·å®ä¾‹
  const capture = new AudioCapture({
    processId: target.pid,
    sampleRate: 48000,
    channels: 2,
    format: 'float32'
  });

  // 3. å¯ç”¨ AI å¤„ç†
  capture.setDenoiseEnabled(true);
  capture.setAGCEnabled(true);
  capture.setEQEnabled(true);

  // 4. æ”¶é›†éŸ³é¢‘æ•°æ®
  const audioChunks = [];
  
  capture.on('data', (event) => {
    audioChunks.push(Buffer.from(event.buffer.buffer));
  });

  // 5. å¯åŠ¨å½•åˆ¶
  await capture.start();
  console.log(`âœ… å¼€å§‹å½•åˆ¶: ${target.name} (${duration} ç§’)`);

  // 6. å®šæ—¶åœæ­¢
  setTimeout(async () => {
    await capture.stop();
    
    // 7. ä¿å­˜ä¸º WAV æ–‡ä»¶
    const wavBuffer = createWavFile(audioChunks, 48000, 2);
    fs.writeFileSync('output.wav', wavBuffer);
    
    console.log('âœ… å½•åˆ¶å®Œæˆ: output.wav');
  }, duration * 1000);
}

// åˆ›å»º WAV æ–‡ä»¶
function createWavFile(chunks, sampleRate, channels) {
  const dataLength = chunks.reduce((sum, buf) => sum + buf.length, 0);
  const wavHeader = Buffer.alloc(44);
  
  // RIFF header
  wavHeader.write('RIFF', 0);
  wavHeader.writeUInt32LE(36 + dataLength, 4);
  wavHeader.write('WAVE', 8);
  
  // fmt chunk
  wavHeader.write('fmt ', 12);
  wavHeader.writeUInt32LE(16, 16);
  wavHeader.writeUInt16LE(3, 20);  // IEEE float
  wavHeader.writeUInt16LE(channels, 22);
  wavHeader.writeUInt32LE(sampleRate, 24);
  wavHeader.writeUInt32LE(sampleRate * channels * 4, 28);
  wavHeader.writeUInt16LE(channels * 4, 32);
  wavHeader.writeUInt16LE(32, 34);
  
  // data chunk
  wavHeader.write('data', 36);
  wavHeader.writeUInt32LE(dataLength, 40);
  
  return Buffer.concat([wavHeader, ...chunks]);
}

// ä½¿ç”¨ç¤ºä¾‹
recordAudio('chrome', 10);  // å½•åˆ¶ Chrome éŸ³é¢‘ 10 ç§’
```

---

## å¸¸è§é—®é¢˜

### Q1: å®‰è£…æ—¶æç¤ºéœ€è¦ç¼–è¯‘ï¼Ÿ

**A**: ä½¿ç”¨ v2.8.0 GitHub Releaseï¼ŒåŒ…å«é¢„ç¼–è¯‘äºŒè¿›åˆ¶ï¼š

```bash
npm install https://github.com/wujelly701/node-windows-audio-capture/tarball/v2.8.0
```

å¦‚æœä»ç„¶éœ€è¦ç¼–è¯‘ï¼Œç¡®ä¿å®‰è£…ï¼š
- Visual Studio 2017+
- Windows SDK
- Python 3.x

---

### Q2: æ— æ³•æ•è· Chrome æ ‡ç­¾é¡µéŸ³é¢‘ï¼Ÿ

**A**: Chrome ä½¿ç”¨å¤šè¿›ç¨‹æ¶æ„ï¼Œéœ€è¦ä¿æŠ¤æ‰€æœ‰å­è¿›ç¨‹ï¼š

```javascript
const processes = await getProcesses();
const chromePids = processes
  .filter(p => p.name.toLowerCase() === 'chrome.exe')
  .map(p => p.pid);

capture.setAllowList(chromePids);
capture.setMuteOtherProcesses(true);
```

---

### Q3: éŸ³é¢‘æœ‰æ‚éŸ³æˆ–å›å£°ï¼Ÿ

**A**: å¯ç”¨ AI é™å™ªå’Œ EQï¼š

```javascript
capture.setDenoiseEnabled(true);
capture.setEQEnabled(true);
capture.setEQBandGain('low', -3);  // å‡å°‘ä½é¢‘å™ªéŸ³
```

---

### Q4: éŸ³é‡å¿½å¤§å¿½å°ï¼Ÿ

**A**: å¯ç”¨ AGC éŸ³é‡å½’ä¸€åŒ–ï¼š

```javascript
capture.setAGCEnabled(true);
capture.setAGCOptions({
  targetLevel: -18,
  maxGain: 25,
  attackTime: 10,
  releaseTime: 100
});
```

---

### Q5: å¦‚ä½•é€‰æ‹©åˆé€‚çš„ Buffer Pool ç­–ç•¥ï¼Ÿ

**A**: 
- **fixed**: å›ºå®šå¤§å°ï¼Œé€‚åˆç¨³å®šè´Ÿè½½
- **adaptive**: è‡ªåŠ¨è°ƒæ•´ï¼Œé€‚åˆå˜åŒ–è´Ÿè½½ï¼ˆæ¨èï¼‰

```javascript
const capture = new AudioCapture({
  bufferPoolStrategy: 'adaptive',  // æ¨è
  bufferPoolSize: 50,              // åˆå§‹å¤§å°
  bufferPoolMin: 50,
  bufferPoolMax: 200
});
```

---

### Q6: WASAPI è¾“å‡ºä»€ä¹ˆæ ¼å¼ï¼Ÿå¦‚ä½•è½¬æ¢ï¼Ÿ

**A**: 
WASAPI éŸ³é¢‘å¼•æ“**å§‹ç»ˆè¾“å‡º Float32 æ ¼å¼**ï¼Œè¿™æ˜¯ Windows çš„å›ºå®šè¡Œä¸ºï¼Œæ— æ³•é€šè¿‡é…ç½®ä¿®æ”¹ã€‚

**é»˜è®¤æ ¼å¼**:
- **æ•°æ®ç±»å‹**: Float32 (32-bit æµ®ç‚¹)
- **å–å€¼èŒƒå›´**: -1.0 ~ 1.0
- **é‡‡æ ·ç‡**: 48000 Hz (å¯é…ç½®)
- **å£°é“æ•°**: 2 (Stereo, å¯é…ç½®)

**å¦‚éœ€å…¶ä»–æ ¼å¼ï¼ˆå¦‚ Int16ï¼‰ï¼Œä½¿ç”¨ AudioProcessingPipeline**:

```javascript
const { AudioCapture } = require('node-windows-audio-capture');
const AudioProcessingPipeline = require('node-windows-audio-capture/lib/audio-processing-pipeline');

// WASAPI æ•è·ï¼ˆFloat32, 48kHz, Stereoï¼‰
const capture = new AudioCapture({ processId: 1234 });

// æ ¼å¼è½¬æ¢ç®¡é“ï¼ˆInt16, 16kHz, Monoï¼‰
const pipeline = new AudioProcessingPipeline('china-asr', {
  quality: 'sinc'  // æ¨èï¼šæœ€é«˜è´¨é‡
});

capture.on('data', (event) => {
  const int16Buffer = pipeline.process(event.buffer);
  sendToASR(int16Buffer);  // å‘é€ Int16 æ•°æ®
});
```

---

### Q7: å¦‚ä½•é™ä½ CPU å ç”¨ï¼Ÿ

**A**: 
1. ç¦ç”¨ä¸éœ€è¦çš„åŠŸèƒ½
2. ä½¿ç”¨è¾ƒä½çš„é‡‡æ ·ç‡
3. ä½¿ç”¨ AudioProcessingPipeline è½¬æ¢ä¸ºè½»é‡æ ¼å¼

```javascript
const capture = new AudioCapture({
  sampleRate: 16000,         // é™ä½é‡‡æ ·ç‡
  channels: 1,               // å•å£°é“
  useExternalBuffer: true,
  bufferPoolStrategy: 'adaptive'
});

// ä»…å¯ç”¨å¿…è¦çš„åŠŸèƒ½
capture.setDenoiseEnabled(false);  // å¦‚ä¸éœ€è¦é™å™ª
capture.setAGCEnabled(true);       // AGC å¾ˆè½»é‡
capture.setEQEnabled(false);       // å¦‚ä¸éœ€è¦ EQ

// å¦‚éœ€ Int16 æ ¼å¼ï¼Œä½¿ç”¨ Pipeline è½¬æ¢
const pipeline = new AudioProcessingPipeline('china-asr', {
  quality: 'linear'  // ä½¿ç”¨è¾ƒå¿«çš„çº¿æ€§æ’å€¼ï¼ˆvs sincï¼‰
});
```

---

### Q8: å¦‚ä½•æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡ï¼Ÿ

**A**: 

```javascript
// æ¯ 2 ç§’è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
setInterval(() => {
  const denoiseStats = capture.getDenoiseStats();
  const agcStats = capture.getAGCStats();
  const eqStats = capture.getEQStats();
  const poolStats = capture.getPoolStats();

  console.log('=== æ€§èƒ½ç»Ÿè®¡ ===');
  
  if (denoiseStats) {
    console.log(`é™å™ª VAD: ${(denoiseStats.vadProbability * 100).toFixed(1)}%`);
    console.log(`é™å™ªå¸§æ•°: ${denoiseStats.framesProcessed}`);
  }
  
  if (agcStats) {
    console.log(`AGC å¢ç›Š: ${agcStats.currentGain.toFixed(2)} dB`);
    console.log(`AGC è¾“å…¥: ${agcStats.averageLevel.toFixed(2)} dBFS`);
  }
  
  if (eqStats) {
    console.log(`EQ çŠ¶æ€: ${eqStats.enabled ? 'âœ…' : 'âŒ'}`);
    console.log(`EQ å¸§æ•°: ${eqStats.framesProcessed}`);
  }
  
  if (poolStats) {
    console.log(`ç¼“å†²æ± é‡ç”¨ç‡: ${(poolStats.reuseRate * 100).toFixed(2)}%`);
    console.log(`ç¼“å†²æ± å¤§å°: ${poolStats.currentPoolSize}`);
  }
}, 2000);
```

---

## æ›´å¤šèµ„æº

### ğŸ“š æ–‡æ¡£

- **å®Œæ•´ API æ–‡æ¡£**: [docs/api.md](./api.md)
- **ç¿»è¯‘è½¯ä»¶é›†æˆæŒ‡å—**: [docs/TRANSLATION_SOFTWARE_INTEGRATION.md](./TRANSLATION_SOFTWARE_INTEGRATION.md)
- **v2.8 å‘å¸ƒè¯´æ˜**: [RELEASE_v2.8.0.md](../RELEASE_v2.8.0.md)
- **v2.7 é™å™ªæŒ‡å—**: [docs/V2.7_RELEASE_NOTES.md](./V2.7_RELEASE_NOTES.md)
- **v2.2 ASR é›†æˆ**: [docs/V2.2_RELEASE_NOTES.md](./V2.2_RELEASE_NOTES.md)
- **v2.1 é™éŸ³æ§åˆ¶**: [docs/V2.1_RELEASE_NOTES.md](./V2.1_RELEASE_NOTES.md)

### ğŸ’» ç¤ºä¾‹ä»£ç 

- [examples/basic-capture.js](../examples/basic-capture.js) - åŸºç¡€æ•è·
- [examples/agc-example.js](../examples/agc-example.js) - AGC ç¤ºä¾‹
- [examples/eq-example.js](../examples/eq-example.js) - EQ ç¤ºä¾‹
- [examples/format-conversion-example.js](../examples/format-conversion-example.js) - ASR æ ¼å¼è½¬æ¢
- [examples/process-capture.js](../examples/process-capture.js) - è¿›ç¨‹æ•è·

### ğŸ”— é“¾æ¥

- **GitHub ä»“åº“**: https://github.com/wujelly701/node-windows-audio-capture
- **Issues**: https://github.com/wujelly701/node-windows-audio-capture/issues
- **Releases**: https://github.com/wujelly701/node-windows-audio-capture/releases

---

## ğŸ‰ æ€»ç»“

**node-windows-audio-capture v2.8.0** æä¾›ï¼š

âœ… **è¿›ç¨‹çº§éŸ³é¢‘æ•è·** - ç²¾å‡†æ•è·ç‰¹å®šåº”ç”¨  
âœ… **åŠ¨æ€é™éŸ³æ§åˆ¶** - 90%+ éŸ³é¢‘çº¯åº¦  
âœ… **AI é™å™ª** - RNNoise å®æ—¶é™å™ª  
âœ… **AGC éŸ³é‡å½’ä¸€åŒ–** - è‡ªåŠ¨ç¨³å®šéŸ³é‡  
âœ… **3-Band EQ** - ä¼˜åŒ–éŸ³è´¨å’Œäººå£°  
âœ… **ASR æ ¼å¼è½¬æ¢** - ä¸€è¡Œä»£ç è½¬æ¢  
âœ… **é›¶é…ç½®å®‰è£…** - é¢„ç¼–è¯‘äºŒè¿›åˆ¶  

**å®Œæ•´éŸ³é¢‘å¤„ç†é“¾**:
```
Process Capture â†’ Dynamic Mute (v2.1) â†’ 
Denoise (v2.7) â†’ AGC (v2.8) â†’ EQ (v2.8) â†’ 
ASR Format (v2.2) â†’ Your Application
```

**æ€§èƒ½æŒ‡æ ‡**:
- éŸ³é¢‘å»¶è¿Ÿ: < 100ms
- æ ¼å¼è½¬æ¢: < 3ms
- CPU å ç”¨: < 6%
- å†…å­˜å ç”¨: ~5 KB
- éŸ³é¢‘çº¯åº¦: 90%+

**å¼€å§‹ä½¿ç”¨**:
```bash
npm install https://github.com/wujelly701/node-windows-audio-capture/tarball/v2.8.0
```

ç¥å¼€å‘é¡ºåˆ©ï¼ğŸš€
