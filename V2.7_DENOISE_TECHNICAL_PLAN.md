# v2.7.0 音频降噪技术方案

**版本**: v1.0  
**日期**: 2025年10月15日  
**优先级**: P0 - 最高优先级  
**状态**: 规划中

---

## 🎯 目标

为 node-windows-audio-capture 集成 **RNNoise 深度学习降噪**，显著提升语音清晰度，优化 ASR 场景表现。

### 核心指标

| 指标 | 目标值 | 测量方式 |
|------|--------|---------|
| 噪音抑制 | 15-20 dB | SNR 对比测试 |
| ASR 准确率提升 | 10-30% | 百度/阿里云/Whisper 对比 |
| 处理延迟 | < 10ms | 性能测试 |
| CPU 开销增加 | < 5% | 长时间监控 |
| 内存增加 | < 10 MB | 稳定性测试 |

---

## 📊 技术背景

### RNNoise 简介

- **开发者**: Mozilla/Xiph.Org
- **算法**: 深度学习（RNN + 全连接层）
- **训练数据**: 大规模语音和噪音数据集
- **优势**: 
  - 优秀的降噪效果（15-25 dB）
  - 低 CPU 占用（< 10% 单核）
  - 实时处理能力
  - 开源 BSD 许可证

### 算法特点

```
输入: 48kHz PCM 音频（480 samples/帧，10ms）
处理: RNN + Pitch Filter + 频域滤波
输出: 降噪后的 PCM 音频
```

**处理流程**：
1. 将音频分帧（10ms）
2. FFT 转换到频域
3. RNN 预测噪音概率
4. 频域滤波
5. IFFT 转换回时域

---

## 🏗️ 架构设计

### 整体流程

```
WASAPI 捕获
    ↓
Zero-Copy Buffer (Float32, 48kHz, Stereo)
    ↓
[可选] 声道转换 (Stereo → Mono)
    ↓
[可选] 格式转换 (Float32 → Int16)
    ↓
RNNoise 降噪处理 (480 samples/帧)
    ↓
输出到 JavaScript (Buffer)
    ↓
ASR API / 用户代码
```

### 集成方式

**选项 1: 静态库链接（推荐）**

```cpp
// 编译 RNNoise 为静态库
deps/rnnoise/
  ├─ include/rnnoise.h
  └─ lib/librnnoise.a

// 在 binding.gyp 中链接
{
  "libraries": ["../deps/rnnoise/lib/librnnoise.a"],
  "include_dirs": ["../deps/rnnoise/include"]
}
```

**选项 2: 源码集成**

```
直接将 RNNoise 源码添加到项目中编译
优点: 简单，无需预编译
缺点: 增加编译时间
```

---

## 💻 API 设计

### JavaScript API

```typescript
interface AudioCaptureOptions {
  // ... 现有选项
  
  effects?: {
    // 降噪配置
    denoise?: boolean | DenoiseConfig;
  };
}

interface DenoiseConfig {
  enabled: boolean;        // 启用降噪，默认 false
  frameSize?: number;      // 帧大小（samples），默认 480
  modelPath?: string;      // 自定义模型路径（未来支持）
}
```

### 使用示例

#### 基础用法

```javascript
const { AudioCapture } = require('node-windows-audio-capture');

// 简单启用
const capture = new AudioCapture({
  processId: 0,
  useExternalBuffer: true,  // 推荐使用 zero-copy
  effects: {
    denoise: true  // 一行启用降噪！
  }
});

capture.on('data', (event) => {
  // event.buffer 已经过降噪处理
  // 直接发送到 ASR API
  console.log('降噪后的音频:', event.buffer.length);
});

await capture.start();
```

#### 高级配置

```javascript
const capture = new AudioCapture({
  processId: 0,
  useExternalBuffer: true,
  effects: {
    denoise: {
      enabled: true,
      frameSize: 480  // 10ms @ 48kHz
    }
  }
});
```

#### 与 ASR 集成

```javascript
const AudioProcessingPipeline = require('node-windows-audio-capture/lib/audio-processing-pipeline');

// 组合降噪 + 格式转换
const capture = new AudioCapture({
  processId: 0,
  useExternalBuffer: true,
  effects: {
    denoise: true  // 降噪
  }
});

// ASR 格式转换（16kHz, Mono, Int16）
const pipeline = new AudioProcessingPipeline('china-asr');

capture.on('data', (event) => {
  // 1. 降噪已完成
  // 2. 格式转换
  const asrReady = pipeline.process(event.buffer);
  
  // 3. 发送到 ASR
  // await sendToASR(asrReady);
});
```

---

## 🔧 C++ 实现

### 核心类设计

```cpp
// src/napi/audio_effects.h

#pragma once
#include <rnnoise.h>
#include <vector>
#include <memory>

namespace AudioCapture {

class DenoiseProcessor {
public:
    DenoiseProcessor(int frame_size = 480);
    ~DenoiseProcessor();
    
    // 处理单帧音频（Float32 或 Int16）
    void ProcessFrame(float* frame, int size);
    void ProcessFrame(int16_t* frame, int size);
    
    // 批量处理
    void ProcessBuffer(float* buffer, int size);
    void ProcessBuffer(int16_t* buffer, int size);
    
    // 获取统计信息
    float GetLastVoiceProbability() const;
    int GetProcessedFrames() const;
    
private:
    DenoiseState* state_;
    int frame_size_;
    int processed_frames_;
    float last_vad_prob_;
    
    std::vector<float> temp_buffer_;  // 临时缓冲区
};

} // namespace AudioCapture
```

### 实现细节

```cpp
// src/napi/audio_effects.cpp

#include "audio_effects.h"
#include <cstring>
#include <stdexcept>

namespace AudioCapture {

DenoiseProcessor::DenoiseProcessor(int frame_size)
    : frame_size_(frame_size), processed_frames_(0), last_vad_prob_(0.0f) {
    
    if (frame_size != 480) {
        throw std::invalid_argument("RNNoise only supports 480 samples/frame");
    }
    
    // 初始化 RNNoise 状态
    state_ = rnnoise_create(nullptr);
    if (!state_) {
        throw std::runtime_error("Failed to create RNNoise state");
    }
    
    temp_buffer_.resize(frame_size);
}

DenoiseProcessor::~DenoiseProcessor() {
    if (state_) {
        rnnoise_destroy(state_);
        state_ = nullptr;
    }
}

void DenoiseProcessor::ProcessFrame(float* frame, int size) {
    if (size != frame_size_) {
        throw std::invalid_argument("Frame size mismatch");
    }
    
    // RNNoise 期望 Float32 输入，范围 [-1, 1]
    last_vad_prob_ = rnnoise_process_frame(state_, frame, frame);
    processed_frames_++;
}

void DenoiseProcessor::ProcessFrame(int16_t* frame, int size) {
    // Int16 → Float32
    for (int i = 0; i < size; i++) {
        temp_buffer_[i] = frame[i] / 32768.0f;
    }
    
    ProcessFrame(temp_buffer_.data(), size);
    
    // Float32 → Int16
    for (int i = 0; i < size; i++) {
        float sample = temp_buffer_[i] * 32768.0f;
        frame[i] = static_cast<int16_t>(
            std::max(-32768.0f, std::min(32767.0f, sample))
        );
    }
}

void DenoiseProcessor::ProcessBuffer(float* buffer, int size) {
    int num_frames = size / frame_size_;
    
    for (int i = 0; i < num_frames; i++) {
        ProcessFrame(buffer + i * frame_size_, frame_size_);
    }
    
    // 处理剩余样本（如果有）
    int remaining = size % frame_size_;
    if (remaining > 0) {
        // 零填充到完整帧
        std::vector<float> padded_frame(frame_size_, 0.0f);
        std::memcpy(padded_frame.data(), buffer + num_frames * frame_size_, 
                    remaining * sizeof(float));
        ProcessFrame(padded_frame.data(), frame_size_);
        std::memcpy(buffer + num_frames * frame_size_, padded_frame.data(), 
                    remaining * sizeof(float));
    }
}

float DenoiseProcessor::GetLastVoiceProbability() const {
    return last_vad_prob_;
}

int DenoiseProcessor::GetProcessedFrames() const {
    return processed_frames_;
}

} // namespace AudioCapture
```

### 集成到 AudioProcessor

```cpp
// src/napi/audio_processor.h

class AudioProcessor : public Napi::ObjectWrap<AudioProcessor> {
public:
    // ... 现有方法
    
    // v2.7: 降噪配置
    Napi::Value SetDenoiseEnabled(const Napi::CallbackInfo& info);
    Napi::Value GetDenoiseEnabled(const Napi::CallbackInfo& info);
    Napi::Value GetDenoiseStats(const Napi::CallbackInfo& info);
    
private:
    // ... 现有成员
    
    // v2.7: 降噪处理器
    std::unique_ptr<DenoiseProcessor> denoise_processor_;
    bool denoise_enabled_;
    
    // 音频数据处理回调（添加降噪）
    void OnAudioData(const std::vector<uint8_t>& data);
};
```

```cpp
// src/napi/audio_processor.cpp

void AudioProcessor::OnAudioData(const std::vector<uint8_t>& data) {
    // 1. Zero-Copy Buffer（如果启用）
    std::shared_ptr<ExternalBuffer> buffer;
    if (useExternalBuffer_) {
        buffer = ExternalBufferFactory::Instance().Create();
        if (buffer && buffer->size() >= data.size()) {
            std::memcpy(buffer->data(), data.data(), data.size());
        }
    }
    
    // 2. 降噪处理（如果启用）
    if (denoise_enabled_ && denoise_processor_) {
        // 假设数据格式为 Float32
        float* audio_data = reinterpret_cast<float*>(
            buffer ? buffer->data() : const_cast<uint8_t*>(data.data())
        );
        int num_samples = data.size() / sizeof(float);
        
        denoise_processor_->ProcessBuffer(audio_data, num_samples);
    }
    
    // 3. 传递到 JavaScript
    if (useExternalBuffer_ && buffer) {
        // Zero-Copy 路径
        auto buffer_value = ExternalBuffer::ToBufferFromShared(env_, buffer, data.size());
        // emit 到 JavaScript
    } else {
        // 传统路径
        auto buffer_value = Napi::Buffer<uint8_t>::Copy(env_, data.data(), data.size());
        // emit 到 JavaScript
    }
}
```

---

## 📦 编译配置

### binding.gyp

```python
{
  "targets": [
    {
      "target_name": "audio_addon",
      "sources": [
        "src/napi/addon.cpp",
        "src/napi/audio_processor.cpp",
        "src/napi/audio_effects.cpp",  # 新增
        # ... 其他源文件
      ],
      "include_dirs": [
        "<!@(node -p \"require('node-addon-api').include\")",
        "src",
        "deps/rnnoise/include"  # RNNoise 头文件
      ],
      "dependencies": [
        "<!(node -p \"require('node-addon-api').gyp\")"
      ],
      "libraries": [
        "../deps/rnnoise/lib/librnnoise.a"  # RNNoise 静态库
      ],
      "cflags!": [ "-fno-exceptions" ],
      "cflags_cc!": [ "-fno-exceptions" ],
      "defines": [ "NAPI_DISABLE_CPP_EXCEPTIONS" ],
      "conditions": [
        ["OS=='win'", {
          "msvs_settings": {
            "VCCLCompilerTool": {
              "ExceptionHandling": 1
            }
          }
        }]
      ]
    }
  ]
}
```

### RNNoise 编译脚本

```bash
# scripts/build-rnnoise.sh (Linux/macOS)

#!/bin/bash
set -e

echo "Building RNNoise..."

# 克隆 RNNoise
if [ ! -d "deps/rnnoise" ]; then
    git clone https://gitlab.xiph.org/xiph/rnnoise.git deps/rnnoise
fi

cd deps/rnnoise

# 配置和编译
./autogen.sh
./configure --disable-shared --enable-static
make

# 创建目录结构
mkdir -p lib include
cp .libs/librnnoise.a lib/
cp include/rnnoise.h include/

echo "RNNoise built successfully!"
```

```powershell
# scripts/build-rnnoise.ps1 (Windows)

Write-Host "Building RNNoise for Windows..."

# 检查 Visual Studio
if (-not (Test-Path "C:\Program Files\Microsoft Visual Studio")) {
    Write-Error "Visual Studio not found!"
    exit 1
}

# 克隆 RNNoise
if (-not (Test-Path "deps\rnnoise")) {
    git clone https://gitlab.xiph.org/xiph/rnnoise.git deps\rnnoise
}

cd deps\rnnoise

# 使用 CMake 编译（需要创建 CMakeLists.txt）
mkdir build -Force
cd build

cmake .. -G "Visual Studio 17 2022" -A x64 `
    -DBUILD_SHARED_LIBS=OFF

cmake --build . --config Release

# 复制文件
Copy-Item Release\rnnoise.lib ..\lib\ -Force
Copy-Item ..\include\rnnoise.h ..\include\ -Force

Write-Host "RNNoise built successfully!"
```

---

## 🧪 测试策略

### 单元测试

```javascript
// test/denoise.test.js

describe('Audio Denoise', () => {
  it('should enable denoise successfully', () => {
    const capture = new AudioCapture({
      processId: 0,
      effects: { denoise: true }
    });
    
    expect(capture.getDenoiseEnabled()).toBe(true);
  });
  
  it('should process audio with denoise', async () => {
    const capture = new AudioCapture({
      processId: 0,
      useExternalBuffer: true,
      effects: { denoise: true }
    });
    
    let dataReceived = false;
    
    capture.on('data', (event) => {
      dataReceived = true;
      expect(event.buffer).toBeDefined();
      expect(event.buffer.length).toBeGreaterThan(0);
    });
    
    await capture.start();
    await new Promise(resolve => setTimeout(resolve, 1000));
    capture.stop();
    
    expect(dataReceived).toBe(true);
  });
  
  it('should provide denoise stats', async () => {
    const capture = new AudioCapture({
      processId: 0,
      effects: { denoise: true }
    });
    
    await capture.start();
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    const stats = capture.getDenoiseStats();
    expect(stats.processedFrames).toBeGreaterThan(0);
    expect(stats.voiceProbability).toBeGreaterThanOrEqual(0);
    expect(stats.voiceProbability).toBeLessThanOrEqual(1);
    
    capture.stop();
  });
});
```

### 音频质量测试

```javascript
// test/audio-quality.test.js

const fs = require('fs');
const { AudioCapture } = require('..');

describe('Audio Quality - Denoise', () => {
  it('should reduce background noise', async () => {
    // 录制 5 秒音频（无降噪）
    const capture1 = new AudioCapture({ processId: 0 });
    const chunks1 = [];
    
    capture1.on('data', (e) => chunks1.push(e.buffer));
    await capture1.start();
    await new Promise(resolve => setTimeout(resolve, 5000));
    capture1.stop();
    
    const noDenoiseAudio = Buffer.concat(chunks1);
    fs.writeFileSync('test/output/no-denoise.raw', noDenoiseAudio);
    
    // 录制 5 秒音频（启用降噪）
    const capture2 = new AudioCapture({
      processId: 0,
      effects: { denoise: true }
    });
    const chunks2 = [];
    
    capture2.on('data', (e) => chunks2.push(e.buffer));
    await capture2.start();
    await new Promise(resolve => setTimeout(resolve, 5000));
    capture2.stop();
    
    const denoiseAudio = Buffer.concat(chunks2);
    fs.writeFileSync('test/output/denoise.raw', denoiseAudio);
    
    // 人工对比（需要转换为 WAV 并播放）
    console.log('✅ Audio files saved for manual comparison');
    console.log('   no-denoise.raw: 原始音频');
    console.log('   denoise.raw: 降噪后音频');
  });
});
```

### ASR 准确率测试

```javascript
// test/asr-accuracy.test.js

const { AudioCapture } = require('..');
const AudioProcessingPipeline = require('../lib/audio-processing-pipeline');

describe('ASR Accuracy - Denoise Impact', () => {
  it('should improve ASR accuracy with denoise', async function() {
    this.timeout(60000);  // 1 分钟测试
    
    // 场景 1: 无降噪
    const capture1 = new AudioCapture({ processId: 0 });
    const pipeline1 = new AudioProcessingPipeline('china-asr');
    const chunks1 = [];
    
    capture1.on('data', (e) => {
      const converted = pipeline1.process(e.buffer);
      chunks1.push(converted);
    });
    
    await capture1.start();
    console.log('🎤 录制 10 秒音频（无降噪）...');
    await new Promise(resolve => setTimeout(resolve, 10000));
    capture1.stop();
    
    const audio1 = Buffer.concat(chunks1);
    
    // 发送到 ASR API（示例）
    // const result1 = await sendToASR(audio1);
    
    // 场景 2: 启用降噪
    const capture2 = new AudioCapture({
      processId: 0,
      effects: { denoise: true }
    });
    const pipeline2 = new AudioProcessingPipeline('china-asr');
    const chunks2 = [];
    
    capture2.on('data', (e) => {
      const converted = pipeline2.process(e.buffer);
      chunks2.push(converted);
    });
    
    await capture2.start();
    console.log('🎤 录制 10 秒音频（启用降噪）...');
    await new Promise(resolve => setTimeout(resolve, 10000));
    capture2.stop();
    
    const audio2 = Buffer.concat(chunks2);
    
    // 发送到 ASR API（示例）
    // const result2 = await sendToASR(audio2);
    
    // 对比准确率
    // expect(result2.accuracy).toBeGreaterThan(result1.accuracy);
    
    console.log('✅ ASR 准确率对比测试完成');
    console.log('   （需要实际 ASR API 才能验证）');
  });
});
```

### 性能测试

```javascript
// test/denoise-performance.test.js

describe('Denoise Performance', () => {
  it('should have low CPU overhead', async () => {
    const capture = new AudioCapture({
      processId: 0,
      useExternalBuffer: true,
      effects: { denoise: true }
    });
    
    const startCPU = process.cpuUsage();
    const startTime = Date.now();
    
    let frameCount = 0;
    capture.on('data', () => frameCount++);
    
    await capture.start();
    await new Promise(resolve => setTimeout(resolve, 30000));  // 30 秒
    capture.stop();
    
    const endCPU = process.cpuUsage(startCPU);
    const duration = (Date.now() - startTime) / 1000;
    
    const cpuPercent = ((endCPU.user + endCPU.system) / 1000000 / duration) * 100;
    
    console.log(`CPU Usage: ${cpuPercent.toFixed(2)}%`);
    console.log(`Frames Processed: ${frameCount}`);
    console.log(`FPS: ${(frameCount / duration).toFixed(1)}`);
    
    expect(cpuPercent).toBeLessThan(15);  // < 15% CPU
  });
  
  it('should have low processing latency', async () => {
    const capture = new AudioCapture({
      processId: 0,
      effects: { denoise: true }
    });
    
    const latencies = [];
    
    capture.on('data', (event) => {
      const now = Date.now();
      const latency = now - event.timestamp;
      latencies.push(latency);
    });
    
    await capture.start();
    await new Promise(resolve => setTimeout(resolve, 10000));
    capture.stop();
    
    const avgLatency = latencies.reduce((a, b) => a + b, 0) / latencies.length;
    const maxLatency = Math.max(...latencies);
    
    console.log(`Average Latency: ${avgLatency.toFixed(2)} ms`);
    console.log(`Max Latency: ${maxLatency} ms`);
    
    expect(avgLatency).toBeLessThan(20);  // < 20ms 平均延迟
    expect(maxLatency).toBeLessThan(50);  // < 50ms 最大延迟
  });
});
```

---

## 📋 开发计划

### 第 1 周：RNNoise 集成

**任务**：
- [ ] 克隆 RNNoise 仓库到 `deps/rnnoise`
- [ ] 编写编译脚本（Windows + Linux）
- [ ] 编译 RNNoise 静态库
- [ ] 验证库文件和头文件正确生成
- [ ] 更新 `binding.gyp` 配置
- [ ] 测试编译 addon

**交付物**：
- `deps/rnnoise/lib/librnnoise.a` (或 `.lib`)
- `deps/rnnoise/include/rnnoise.h`
- `scripts/build-rnnoise.sh` / `.ps1`
- 编译成功的 addon

---

### 第 2 周：C++ 实现和绑定

**任务**：
- [ ] 实现 `DenoiseProcessor` 类
- [ ] 集成到 `AudioProcessor::OnAudioData()`
- [ ] 实现 JavaScript API 绑定
  - `setDenoiseEnabled(enabled)`
  - `getDenoiseEnabled()`
  - `getDenoiseStats()`
- [ ] 添加配置选项解析
- [ ] 处理不同音频格式（Float32/Int16）
- [ ] 单元测试

**交付物**：
- `src/napi/audio_effects.h` / `.cpp`
- 更新的 `audio_processor.cpp`
- 基础单元测试通过

---

### 第 3 周：测试、文档和示例

**任务**：
- [ ] 完整测试套件
  - 功能测试（启用/禁用）
  - 音频质量测试（A/B 对比）
  - ASR 准确率测试（可选）
  - 性能测试（CPU/延迟）
- [ ] 更新 README.md
- [ ] 更新 API 文档
- [ ] 编写使用示例
  - 基础降噪示例
  - 与 ASR 集成示例
  - 性能调优示例
- [ ] 更新 TypeScript 类型定义

**交付物**：
- 完整测试套件（90%+ 覆盖率）
- 更新的文档
- `examples/denoise-example.js`
- 更新的 `index.d.ts`

---

## 📝 文档更新清单

### README.md

- [ ] 添加 v2.7 特性说明（降噪）
- [ ] 更新快速开始示例
- [ ] 添加降噪 API 文档
- [ ] 更新路线图

### API 文档

- [ ] 新增 `effects.denoise` 配置说明
- [ ] 新增 `setDenoiseEnabled()` 方法
- [ ] 新增 `getDenoiseStats()` 方法
- [ ] 添加音频质量对比数据

### 示例代码

- [ ] `examples/denoise-basic.js` - 基础降噪
- [ ] `examples/denoise-asr-integration.js` - ASR 集成
- [ ] `examples/denoise-performance-test.js` - 性能测试

### TypeScript 定义

```typescript
// index.d.ts 更新

interface AudioCaptureOptions {
  // ... 现有选项
  
  effects?: {
    denoise?: boolean | DenoiseConfig;
  };
}

interface DenoiseConfig {
  enabled: boolean;
  frameSize?: number;
}

interface DenoiseStats {
  processedFrames: number;
  voiceProbability: number;
}

class AudioCapture extends EventEmitter {
  // ... 现有方法
  
  setDenoiseEnabled(enabled: boolean): void;
  getDenoiseEnabled(): boolean;
  getDenoiseStats(): DenoiseStats;
}
```

---

## 🚀 发布策略

### v2.7.0-alpha (2025年11月底)

**包含**：
- ✅ 自适应 Buffer Pool
- ✅ RNNoise 降噪（基础功能）
- ✅ 基础测试套件

**目标用户**：早期测试者

---

### v2.7.0-beta (2025年12月初)

**包含**：
- ✅ Alpha 所有特性
- ✅ 完整测试覆盖
- ✅ 性能优化
- ✅ 完整文档

**目标用户**：Beta 测试者

---

### v2.7.0 (2025年12月中旬)

**包含**：
- ✅ Beta 所有特性
- ✅ Bug 修复
- ✅ 完整示例代码
- ✅ ASR 准确率验证数据

**目标用户**：所有用户

---

## 📊 成功标准

### 功能标准

- [x] RNNoise 成功编译和链接
- [ ] 降噪功能正常工作
- [ ] API 使用简单（一行启用）
- [ ] 向后兼容（opt-in 设计）

### 性能标准

- [ ] 噪音抑制 ≥ 15 dB
- [ ] 处理延迟 < 10ms
- [ ] CPU 开销 < 5%
- [ ] 内存增加 < 10 MB

### 质量标准

- [ ] ASR 准确率提升 10-30%
- [ ] 音频无明显失真
- [ ] 长时间运行稳定（1小时+）
- [ ] 测试覆盖率 > 90%

### 用户体验标准

- [ ] 配置简单（默认参数即可用）
- [ ] 文档清晰完整
- [ ] 示例代码丰富
- [ ] 错误处理友好

---

## 🔍 风险评估

| 风险 | 影响 | 概率 | 缓解措施 |
|------|------|------|---------|
| RNNoise 编译困难 | 高 | 中 | 提前验证，提供详细文档 |
| CPU 开销过高 | 中 | 低 | 性能测试，opt-in 设计 |
| 音频质量下降 | 高 | 低 | A/B 测试，可配置强度 |
| Windows 编译问题 | 中 | 中 | 提供预编译库选项 |
| 内存泄漏 | 高 | 低 | Valgrind 测试，代码审查 |

---

## 📞 支持和反馈

### 开发过程中

- 定期更新进度（每周）
- GitHub Issues 跟踪问题
- Discord/Slack 技术讨论

### 发布后

- 收集用户反馈
- 快速修复关键 bug
- 持续优化性能

---

**文档作者**: GitHub Copilot  
**审核状态**: 待审核  
**下一步**: 开始第 1 周开发工作
